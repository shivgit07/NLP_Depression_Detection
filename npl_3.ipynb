{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samar-Agarwal/Detecting-Depression-through-Tweets/blob/main/npl_wids_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cOd3RIWsxEUR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ewjQ9LmnsqC",
        "outputId": "dc20198e-be82-4dd4-e4bc-eb60f87e354b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OyQPcR3wnuW4"
      },
      "outputs": [],
      "source": [
        "data =pd.read_csv(\"drive/MyDrive/WIDS_NLP_Project/dataset2.csv\", on_bad_lines = 'skip')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['Sentiment', 'SentimentText']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJXwobRfodTH",
        "outputId": "e62edffa-ee14-46e0-8b3e-edd351259ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1580354\n",
            "1576870\n"
          ]
        }
      ],
      "source": [
        "data['SentimentText'] = data['SentimentText'].apply(lambda x: x.lower()) # lowering all alphabets\n",
        "data['SentimentText'] = data['SentimentText'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))  #using re module for stooping\n",
        "\n",
        "print(data[ data['Sentiment'] == 1].size)\n",
        "print(data[ data['Sentiment'] == 0].size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CfinLyxQpYHR"
      },
      "outputs": [],
      "source": [
        "max_fatures = 20000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['SentimentText'].values)\n",
        "X = tokenizer.texts_to_sequences(data['SentimentText'].values)\n",
        "X = pad_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mT9h33NuoBaE"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PPcp7YRfoBaF"
      },
      "outputs": [],
      "source": [
        "documents = [_text.split() for _text in data.SentimentText]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G_JsaqmRoBaF"
      },
      "outputs": [],
      "source": [
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=W2V_MIN_COUNT, \n",
        "                                            workers=12)\n",
        "\n",
        "\n",
        "w2v_model.build_vocab(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXfdhZ9ioBaF",
        "outputId": "ae3339f0-8a88-4720-f06b-85c50e2c6c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size 45138\n"
          ]
        }
      ],
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pjBIkBvE_Uac",
        "outputId": "e5ca134b-c41b-4a91-bb7a-07e11856de25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYQad0FY_bYR",
        "outputId": "663657e4-516d-4f87-9f31-1a338a484c25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 12283898799975946715\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14415560704\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 8730480443657955857\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx5ZMlg4oBaH",
        "outputId": "b9aec57d-f415-4f9a-d66f-5ec16ee95da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36min 35s, sys: 11.1 s, total: 36min 46s\n",
            "Wall time: 19min 58s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(488066199, 663205824)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "%%time\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4cr5jNEO8joM"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(data['SentimentText'].values) \n",
        "X = tokenizer.texts_to_sequences(data['SentimentText'].values) \n",
        "X = pad_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyI0z29voBaH",
        "outputId": "fc02715f-2dcb-4337-f307-2c3396e97b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size is  820831\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "print('Vocab Size is ',vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki_pnTg-oBaI",
        "outputId": "2a2ea11a-b507-429f-ba49-6415ae53e750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(820831, 300)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "embedding_matrix = np.zeros(( vocab_size, W2V_SIZE))\n",
        "for word , i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WKL0WmHoBaI",
        "outputId": "715a91bb-4550-49f2-8f51-eee0576a8b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 41, 300)           246249300 \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 41, 300)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 41, 106)           172568    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 53)                33920     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 108       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246,455,896\n",
            "Trainable params: 206,596\n",
            "Non-trainable params: 246,249,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "lstm_out = 53\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, W2V_SIZE, weights = [ embedding_matrix], input_length = X.shape[1], trainable = False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(2*lstm_out, dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(lstm_out, dropout=0.2))\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
        "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PPzpC9wCoBaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d31a0d-b87c-44cf-bc66-1d0ad394c6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(773519, 41) (773519, 2)\n",
            "(331509, 41) (331509, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y = pd.get_dummies(data['Sentiment']).values\n",
        "X_new, X_del, Y_new, Y_del = train_test_split(X,Y, test_size = 0.3, random_state = 42)\n",
        "X_train,X_test,Y_train, Y_test =train_test_split(X_new,Y_new, test_size = 0.3, random_state =14 )\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0llpN3dtH2Vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f46273-419d-4193-fd9b-ceabaf5504d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "3022/3022 [==============================] - 43s 11ms/step - loss: 0.4341 - accuracy: 0.7976\n",
            "Epoch 2/2\n",
            "3022/3022 [==============================] - 35s 11ms/step - loss: 0.4040 - accuracy: 0.8150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb77a65cb20>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 2\n",
        "model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ii-KTVVAbyRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b10121-e7d4-428c-ca4e-a75274fa9f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1295/1295 [==============================] - 8s 5ms/step - loss: 0.3834 - accuracy: 0.8262\n",
            "score: 0.38\n",
            "acc: 0.83\n"
          ]
        }
      ],
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential((Dense(2,activation='sigmoid')))\n",
        "model2.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "# print(model2.summary())"
      ],
      "metadata": {
        "id": "xcVw7DB1Y4ka"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "epochs = 7\n",
        "model2.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z34BBiLtgFdl",
        "outputId": "539c196a-7dea-4f88-9300-b65a0b7df25d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 1958.4371 - accuracy: 0.5096\n",
            "Epoch 2/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 19.6084 - accuracy: 0.5206\n",
            "Epoch 3/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 18.7568 - accuracy: 0.5232\n",
            "Epoch 4/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 19.3559 - accuracy: 0.5228\n",
            "Epoch 5/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 18.6909 - accuracy: 0.5229\n",
            "Epoch 6/7\n",
            "1511/1511 [==============================] - 4s 3ms/step - loss: 18.3832 - accuracy: 0.5234\n",
            "Epoch 7/7\n",
            "1511/1511 [==============================] - 5s 3ms/step - loss: 19.2930 - accuracy: 0.5230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb86b76e4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score,acc = model2.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pPyzZrogQf0",
        "outputId": "d088db7d-4f69-4d2e-824e-09ef10c23b03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "648/648 [==============================] - 1s 2ms/step - loss: 18.6089 - accuracy: 0.5229\n",
            "score: 18.61\n",
            "acc: 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogReg:\n",
        "    \"\"\"\n",
        "    Class to represent a logistic regression model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, l_rate, epochs, n_features):\n",
        "        \"\"\"\n",
        "        Create a new model with certain parameters.\n",
        "\n",
        "        :param l_rate: Initial learning rate for model.\n",
        "        :param epoch: Number of epochs to train for.\n",
        "        :param n_features: Number of features.\n",
        "        \"\"\"\n",
        "        self.l_rate = l_rate\n",
        "        self.epochs = epochs\n",
        "        self.coef = [0.0] * n_features\n",
        "        self.bias = 0.0\n",
        "\n",
        "    def sigmoid(self, score, threshold=20.0):\n",
        "        \"\"\"\n",
        "        Prevent overflow of exp by capping activation at 20.\n",
        "\n",
        "        :param score: A real valued number to convert into a number between 0 and 1\n",
        "        \"\"\"\n",
        "        # print(score)\n",
        "        # print(abs(score))\n",
        "        # print(threshold)\n",
        "        # print(abs(score)>threshold)\n",
        "        if (abs(score) > threshold):\n",
        "            score = threshold * sign(score)\n",
        "        activation = exp(score)\n",
        "        return activation / (1.0 + activation)\n",
        "\n",
        "    def predict(self, features):\n",
        "        \"\"\"\n",
        "        Given an example's features and the coefficients, predicts the class.\n",
        "\n",
        "        :param features: List of real valued features for a single training example.\n",
        "\n",
        "        :return: Returns the predicted class (either 0 or 1).\n",
        "        \"\"\"\n",
        "        # print(features)\n",
        "        # print(self.coef)\n",
        "        # print(self.bias)\n",
        "        value = sum([features[i]*self.coef[i] for i in range(len(features))]) + self.bias\n",
        "        #print(value)\n",
        "        return self.sigmoid(value)\n",
        "\n",
        "    def sg_update(self, features, label):\n",
        "        \"\"\"\n",
        "        Computes the update to the weights based on a predicted example.\n",
        "\n",
        "        :param features: Features to train on.\n",
        "        :param label: Corresponding label for features.\n",
        "        \"\"\"\n",
        "        yhat = self.predict(features)\n",
        "        e = label - yhat\n",
        "        self.bias = self.bias + self.l_rate * e * yhat * (1-yhat)\n",
        "        for i in range(len(features)):\n",
        "          # if (i==0) : print(e,label,yhat)\n",
        "          self.coef[i] = (self.coef[i]) + (self.l_rate * e * yhat * (1-yhat) * features[i])\n",
        "          # if (i==0) : print(self.coef[0])\n",
        "        return\n",
        "\n",
        "    def train(self, X, y):\n",
        "        \"\"\"\n",
        "        Computes logistic regression coefficients using stochastic gradient descent.\n",
        "\n",
        "        :param X: Features to train on.\n",
        "        :param y: Corresponding label for each set of features.\n",
        "\n",
        "        :return: Returns a list of model weight coefficients where coef[0] is the bias.\n",
        "        \"\"\"\n",
        "        for epoch in range(self.epochs):\n",
        "            print(epoch)\n",
        "            for features, label in zip(X, y):\n",
        "                self.sg_update(features, label)\n",
        "        return self.bias, self.coef"
      ],
      "metadata": {
        "id": "3z6ovvhKu3j1"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(y_bar, y_pred):\n",
        "    \"\"\"\n",
        "    Computes what percent of the total testing data the model classified correctly.\n",
        "\n",
        "    :param y_bar: List of ground truth classes for each example.\n",
        "    :param y_pred: List of model predicted class for each example.\n",
        "\n",
        "    :return: Returns a real number between 0 and 1 for the model accuracy.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    for i in range(len(y_bar)):\n",
        "        if y_bar[i] == y_pred[i]:\n",
        "            correct += 1\n",
        "    accuracy = (correct / len(y_bar)) * 100.0\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Xf2fnby8u6IP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = X_train[0]\n",
        "print(sum([features1[i] for i in range(len(features1))]))\n",
        "values = []\n",
        "for yu in Y_train :\n",
        "  val =2*yu[0] + yu[1]\n",
        "  if val not in values:\n",
        "    values.append(val)\n",
        "print(values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QTbuf6e6yD9",
        "outputId": "329df59b-8a31-48c0-941e-0ac4c366d9ab"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66854\n",
            "[1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Model\n",
        "from math import exp\n",
        "from numpy import sign\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCHS= 10\n",
        "logreg = LogReg(LEARNING_RATE, EPOCHS, len(X_train[0]))\n",
        "bias_logreg, weights_logreg = logreg.train(X_train, Y_train[:,0])\n",
        "y_logistic = [round(logreg.predict(example)) for example in Y_test]\n",
        "\n",
        "# Compare accuracies\n",
        "accuracy_logistic = get_accuracy(y_logistic, Y_test[:,0])\n",
        "print('Logistic Regression Accuracy: {:0.3f}'.format(accuracy_logistic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFdoM4nJu8UA",
        "outputId": "63ca5a3f-61ea-4a25-ab39-c7f562d7be5d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "Logistic Regression Accuracy: 50.044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('drive/MyDrive/lstm_model', 'wb') as picklefile:\n",
        "    pickle.dump(model,picklefile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB96WSAVDg6F",
        "outputId": "939d7353-b3ea-431b-eba0-e1a27fea894b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('linear_model', 'wb') as picklefile:\n",
        "    pickle.dump(model2,picklefile)"
      ],
      "metadata": {
        "id": "iVAXJWFWDu3J"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bias_logreg,weights_logreg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxO7ar6hFxER",
        "outputId": "43977359-e3ff-4114-e875-f05a6ab879d0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.024538496135856923 [0.0, 0.0, -5.522860497728673e-17, -4.507503836992401e-15, -1.1564020211398037e-14, -3.9438746814280475e-13, 2.2077016292431663e-05, 0.00019435812850934314, 0.0048836384107786065, 0.012021993157683432, 0.03245119341177947, 0.1005207748376716, 0.20376911579444526, 0.44439708454755306, 0.7726877952584621, 1.2211557660842074, 390.16433560895405, -7430.4351085862345, 18.40399834222648, 2.1153038502163395, 1.8718687046016873, -0.5330140973605441, 3.0835451788008785, 34.82985676329183, -0.8317367157702044, -8330.414863373106, -1.9525043643131057, -489.40509383174884, -22.548532228592016, 27.17408721116987, 4.462190492484859, -273.1285287492319, -152.40843124726487, -98.69090426873194, -379.53653401765683, -2167.9197595616633, -37.30633060181296, -38.99135168414841, -33.26552020102096, -39.36143439545421, 62.06236692692242]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -0.024538496135856923 [0.0, 0.0, -5.522860497728673e-17, -4.507503836992401e-15, -1.1564020211398037e-14, -3.9438746814280475e-13, 2.2077016292431663e-05, 0.00019435812850934314, 0.0048836384107786065, 0.012021993157683432, 0.03245119341177947, 0.1005207748376716, 0.20376911579444526, 0.44439708454755306, 0.7726877952584621, 1.2211557660842074, 390.16433560895405, -7430.4351085862345, 18.40399834222648, 2.1153038502163395, 1.8718687046016873, -0.5330140973605441, 3.0835451788008785, 34.82985676329183, -0.8317367157702044, -8330.414863373106, -1.9525043643131057, -489.40509383174884, -22.548532228592016, 27.17408721116987, 4.462190492484859, -273.1285287492319, -152.40843124726487, -98.69090426873194, -379.53653401765683, -2167.9197595616633, -37.30633060181296, -38.99135168414841, -33.26552020102096, -39.36143439545421, 62.06236692692242]"
      ],
      "metadata": {
        "id": "mc1I-l5tIioA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/zNnYuYLTnvyz6f/H8M0I",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}